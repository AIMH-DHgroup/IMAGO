# IMAGO Triplifier

The IMAGO Triplifier is a command‑line utility for converting structured metadata about medieval works and places into RDF. It is part of the [IMAGO project](https://imagoarchive.it/), which curates digital descriptions
of early manuscripts, printed editions and the geographical context of Dante Alighieri’s works. The triplifier ingests JSON datasets describing either lemmas (author–work pairs) or toponyms (named places) and produces RDF graphs conforming to the IMAGO ontology, an extension of CIDOC CRM and FRBRoo. The resulting graphs can be written to Turtle files or uploaded directly to an Apache Jena Fuseki triple store.

## Features

- Two data pipelines – The tool can process both toponyms from Dante’s works and lemmas describing author–work pairs recorded in the IMAGO archive. Each dataset is parsed with [Jackson] to Java Plain Old Java Objects (POJOs), transformed into RDF individuals using Apache Jena and the IMAGO ontology, and then serialised as Turtle.

- Ontology driven – The `Vocabulary` utility maps classes and properties from CIDOC CRM (e.g., `E53_Place`), FRBRoo/ILRmoo (e.g., `F28_Expression_Creation`), GeoSPARQL, and IMAGO‑specific classes such as `Author`, `Toponym`, `Manuscript` and `Printed_Edition`. It shields developers from typing long IRIs and ensures semantic consistency.

- Configurable ingestion – A simple `config.properties` file defines the location of the IMAGO ontology (e.g. `https://imagoarchive.it/onto/IMAGO-270222.ttl`), the input JSON datasets (`json.toponyms` and `json.imago`), the Fuseki dataset URL, and login credentials.

- Triple store integration – Once a model is generated, it may be optionally loaded into a named graph of a Jena Fuseki server. Graphs toponyms and archive are used by default for toponyms and lemmas respectively, while a hidden option uploads an additional associations file to the mmm graph.

- Sample SPARQL queries – The SPARQL directory contains ready‑made queries for exploring the knowledge base: retrieving lemmas, manuscripts, genres, toponyms and geospatial features. They can be run via the Fuseki SPARQL endpoint after loading data.

## Prerequisites

To build and run the triplifier you need:
| Requirement     | Version                                                                                 |
| --------------- | --------------------------------------------------------------------------------------- |
| Java            | Java 8 or higher (JDK 1.8+)                                                             |
| Maven           | Maven 3.x to compile and package the code                                               |
| Apache Fuseki   | (optional) a Fuseki 2.x server with a dataset configured                                |
| Internet access | Required when downloading the IMAGO ontology or when uploading to a remote triple store |

## Supported RDF output

Apache Jena’s RIOT framework can write models to several RDF serialisation formats. The triplifier writes Turtle files (`.ttl`) by default, but Jena also supports JSON‑LD, N‑Triples, TriG, RDF/XML, TriX, RDF/JSON and RDF Binary. Note that RDF/JSON is different from JSON‑LD—it is a direct encoding of triples in JSON. You can
adapt the source code to write other formats if required.

## Project structure
```graphql
triplifier/
├── SPARQL/                 # Example SPARQL queries
│   ├── queries.rq          # Queries over lemmas and manuscripts
│   ├── queriesItineraria.rq# Queries related to travel literature
│   ├── queries_toponyms.rq # Simple queries on Dante’s toponyms
│   └── GeoSPARQL/          # GeoSPARQL queries and a README
├── input_imago.json        # Sample IMAGO lemma dataset (not tracked by git)
├── toponyms.json           # Sample Dante toponyms dataset (not tracked by git)
├── pom.xml                 # Maven project descriptor
├── src/main/java/
│   ├── cnr/isti/aimh/imago/core/   # Main program (ImagoTriplifier.java)
│   ├── cnr/isti/aimh/imago/models/ # Model builder classes
│   ├── cnr/isti/aimh/imago/pojo/   # POJO classes for JSON mapping
│   └── cnr/isti/aimh/imago/util/   # Utilities: config, Fuseki, vocabulary
└── target/                 # Compiled classes (generated by Maven)
```

## Core classes

- `ImagoTriplifier` (in `cnr.isti.aimh.imago.core`) – The entry point of the application. It reads configuration values, presents a menu to the user (`D` for Dante toponyms, `I` for IMAGO lemmas, `E` to exit, `M` for loading an association model), calls `JacksonImport` to parse JSON data, uses `ModelToponyms` or `ModelImago` to construct RDF models, writes Turtle files (toponyms-model.ttl or imago-model.ttl) and, if
configured, uploads the models to a Fuseki dataset.

- `ModelImago` – Imports the IMAGO ontology and populates it with individuals representing lemmas. It creates resources for authors, works, expression creations, places, manuscripts and printed editions based on the fields present in the IMAGO JSON. It uses blank nodes for intermediate resources (e.g., geographic coordinates) and sets language tags on literal strings where appropriate.

- `ModelToponyms` – Similar to `ModelImago` but specialised for Dante’s toponyms. It creates resources for each toponym, attaches multilingual labels, links the toponym to its place, encodes coordinates using WKT, and connects the toponym to the relevant work and textual fragment.

- `ConfigProperties` – Reads a simple key–value file (`config.properties`) from the project root and exposes getters for the dataset URL, ontology URL, JSON file paths and Fuseki credentials.

- `Fuseki` – Wraps Jena’s `RDFConnection` API. It uses `RDFConnectionFactory.connectPW` to authenticate and provides methods for uploading an `OntModel` or a file to a named graph in a Fuseki dataset.

- `JacksonImport` – Uses the Jackson library to parse JSON into lists of `Toponym` or `Root` objects, depending on the chosen ingestion mode.

- `Vocabulary` – Centralises all RDF resources and properties used in the models. It defines URIs for CRM classes (e.g., `E53_Place`), ILRmoo classes (e.g., `F2_Expression`, `F28_Expression_Creation`), GeoSPARQL (`asWKT`) and IMAGO‑specific classes and properties.

## Configuring the triplifier

Before running the program, create a file named `config.properties` in the project root (it is listed in .gitignore so it will not be committed). Populate it with values like the following:

```properties
# Location of the Fuseki dataset (without trailing slash)
dataset.url=DATASET_URL
# Absolute or remote URL of the IMAGO ontology
imago.ontology=ONTOLOGY_URL
# Path to your Dante toponyms JSON
json.toponyms=/path/to/JSON_FILE_OF_TOPONYMS.json
# Path to your IMAGO lemma JSON
json.imago=/path/to/JSON_FILE_OF_LEMMAS.json
# Fuseki credentials (omit if Fuseki is public)
fuseki.user=USER
fuseki.pw=PASSWORD
```

Adjust the file names and credentials as appropriate. If you do not wish to upload data to a triple store, you can leave `dataset.url`, `fuseki.user` and `fuseki.pw` empty; the tool will still write local Turtle files.

## Building the project

1. Ensure you have Java and Maven installed. Check your versions with `java -version` and `mvn -version`.

2. Navigate to the `triplifier` directory and run:

```bash
mvn clean package
```
Maven downloads dependencies (Apache Jena, Jackson) and compiles the source. The compiled classes will appear under `target/classes`.

3. (Optional) To build an executable JAR you can add the Maven maven-assembly-plugin or similar. Alternatively, run the program directly from the compiled classes using the java command.

## Running the triplifier

After building, you can run the application either via Maven or directly with java. The main class is cnr.isti.aimh.imago.core.ImagoTriplifier.

### Using Maven
```bash
mvn -q exec:java \
  -Dexec.mainClass=cnr.isti.aimh.imago.core.ImagoTriplifier
```

### Using java
```bash
java -cp target/classes:$(mvn -q -Dexec.classpathScope=runtime \
     -Dexec.executable=echo \
     -Dexec.args='%classpath' \
     --non-recursive exec:exec) \
     cnr.isti.aimh.imago.core.ImagoTriplifier
```

When you run the program, an interactive menu appears:

```text
**************************************
****            Menu            ******
**************************************
*    [D]ante's toponyms triplify     *
*    [I]mago triplify                *
*    [E]xit                          *
**************************************
Insert your choice:
```

Choose `D` to parse the toponyms JSON and build an RDF model of Dante’s toponyms. Choose `I` to parse the IMAGO lemma JSON and generate an RDF model of authors, works, manuscripts and printed editions.
Both operations write a Turtle file (`toponyms-model.ttl` or `imago-model.ttl` in the current directory). If `dataset.url` and credentials are specified, the model is also uploaded to the named graph `toponyms` or `archive` of your Fuseki dataset. Type `E` to terminate the program.

Hidden option `M` – The source code defines a case `M` that reads a Turtle file named associazioni.ttl and uploads it to the mmm graph. This option does not appear in the menu; you can still type M at the prompt to use it. It may be used for custom linksets between IMAGO resources.

## Input data format

### Dante toponyms

The toponyms JSON is an array of objects, each describing a place name appearing in Dante’s works. Important fields include:

- `name` and `lemma` – The canonical Latin form of the toponym.

- `labelIta` and `labelEng` – Italian and English labels.

- `work` – An object with `name` and `iri` of the work in which the toponym appears (e.g. `"Monarchia"` and its Wikidata IRI).

- `context` – A snippet of the text with the toponym highlighted.

- `placeText` – Bibliographic reference of the occurrence (e.g. “Mon. II viii 7”).

- `iriWD`, `iri_pleiades`, `latitude`, `longitude` – Links to Wikidata and Pleiades plus WGS‑84 coordinates. Coordinates are converted to WKT points in the model.

- `occDeVulgari`, `occEgloge`, etc. – Occurrence counters for Dante’s works. These can be used to link the toponym to specific expression creations (e.g. the F28 node representing De Vulgari Eloquentia).

Only a subset of fields is required; missing labels or Pleiades identifiers are handled gracefully.

### IMAGO lemmas

The IMAGO lemma dataset (`input_imago.json`) is an array of “root” objects. Each object has an id and a nested lemma containing rich metadata:

- **Author** – An object with an `iri` linking to a MIRABILE or other authority record, the `name` of the author and optional `alias` list. An `authorDate` object may specify birth/death dates with uncertainty flags. These values are mapped to the `Author` resource in the ontology, and the alias list is attached using the `has_alias` property.

- **Work** – Identified by an `iri`, `title` and optional alias list. The work is treated as an `F2_Expression` in FRBRoo terms. The main lemma resource (an `F28_Expression_Creation`) is linked to the work via R17_created and to the author via `P14_carried_out_by`.

- **Abstract** and review flags – Short descriptions or free text about the work; included in the model using the `has_abstract` property.

- **Genres** – A list of objects with `iri` and `name`; each is linked from the lemma using the `has_genre` property.

- **Places** – Optional places associated with the work. Each place includes labels in multiple languages, a country object and `coordinates` (WKT `Point` strings). These become `E53_Place` individuals linked via `P7_took_place_at` or similar properties.

- **Manuscripts** – A list of manuscript descriptions. Each manuscript contains a signature (shelfmark), folios, notes, an optional date range, a `library` object (with IRIs and labels) and an `author` (copyist) name.
Additional nested properties capture sources, digital images, decoration descriptions and URLs. Manuscripts are modelled as `Manuscript` individuals with a corresponding `Manifestation_Creation`.

- **Print editions** – Similar to manuscripts but represent printed editions of the work. Fields include publication place (with coordinates), notes, pages, format, editor/curator names and bibliographic sources.

The JSON schema is extensive; only the fields relevant to RDF are used.

## Uploading to Fuseki

If you specify `dataset.url` and credentials, the triplifier will attempt to connect to the dataset using Jena’s `RDFConnectionFactory.connectPW`. The model is then uploaded with a `PUT` to the graph at
`{dataset.url}/archive` or `{dataset.url}/toponyms`. Ensure that the target dataset exists and that your user has permission to perform updates. You can verify the results by visiting the Fuseki UI at `${dataset.url}` and using the SPARQL editor to query the graphs.

## Exploring the data with SPARQL

The SPARQL folder provides query examples for analysis and
visualisation. You can run them from the command line with
curl/wget, via the Fuseki web interface or with a SPARQL client.

Some illustrative queries include:
| File                   | Description                                                         |
| ---------------------- | ------------------------------------------------------------------- |
| `queries.rq`           | Extract all lemmas, list manuscripts ordered by place and library, find works in the same manuscript or manuscripts for a given lemma. |
| `queriesItineraria.rq` | Queries centred on travel literature (e.g., works of the genre `Cartography`, works mentioning the city of Genoa, or printed editions published in Bologna).                                     |
| `queries_toponyms.rq`  | Count toponyms per work and list toponyms with the works in which they appear.                                                        |
| `GeoSPARQL/gsq*.rq`    | GeoSPARQL queries: works mentioning places in France, places within a buffer around the Via Francigena, or places in Italy mentioned in fifteenth‑century manuscripts.                                   |

Detailed explanations of the GeoSPARQL queries and their results are in `SPARQL/GeoSPARQL/GeoSPARQL_queries.md`. Many of the queries rely on GeoSPARQL functions such as geof:sfWithin and fetch country geometries
from external endpoints.

## Extending the tool

The triplifier is designed for IMAGO’s needs but can be adapted to other datasets:

- Different ontologies: Point the `imago.ontology` property to a different ontology and adjust the `Vocabulary` class accordingly. Jena makes it straightforward to read alternative RDF/Turtle ontologies and
create instances.

- Additional input formats: The Jackson mapper expects JSON arrays. To support CSV or XML, add a new parser in the util package.

- Alternative output formats: Replace the calls to `RDFDataMgr.write(…, Lang.TURTLE)` with another language supported by Jena (e.g., `Lang.JSONLD` or `Lang.TRIG`).
